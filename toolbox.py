import importlib
import time
import inspect
import re
import os
import base64
import gradio
import shutil
import glob
import logging
import uuid
from functools import wraps
from shared_utils.config_loader import get_conf
from shared_utils.config_loader import set_conf
from shared_utils.config_loader import set_multi_conf
from shared_utils.config_loader import read_single_conf_with_lru_cache
from shared_utils.advanced_markdown_format import format_io
from shared_utils.advanced_markdown_format import markdown_convertion
from shared_utils.key_pattern_manager import select_api_key
from shared_utils.key_pattern_manager import is_any_api_key
from shared_utils.key_pattern_manager import what_keys
from shared_utils.connect_void_terminal import get_chat_handle
from shared_utils.connect_void_terminal import get_plugin_handle
from shared_utils.connect_void_terminal import get_plugin_default_kwargs
from shared_utils.connect_void_terminal import get_chat_default_kwargs
from shared_utils.text_mask import apply_gpt_academic_string_mask
from shared_utils.text_mask import build_gpt_academic_masked_string
from shared_utils.text_mask import apply_gpt_academic_string_mask_langbased
from shared_utils.text_mask import build_gpt_academic_masked_string_langbased
from shared_utils.map_names import map_friendly_names_to_model
from shared_utils.map_names import map_model_to_friendly_names
from shared_utils.map_names import read_one_api_model_name
from shared_utils.handle_upload import html_local_file
from shared_utils.handle_upload import html_local_img
from shared_utils.handle_upload import file_manifest_filter_type
from shared_utils.handle_upload import extract_archive
from typing import List
pj = os.path.join
default_user_name = "default_user"

"""
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
ç¬¬1éƒ¨åˆ†
é–¢æ•°ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®å…¥å‡ºåŠ›æ¥ç¶šã‚¨ãƒªã‚¢
    - ChatBotWithCookies:   Cookieã‚’æŒã¤Chatbotã‚¯ãƒ©ã‚¹ï¼Œã‚ˆã‚Šå¼·åŠ›ãªæ©Ÿèƒ½ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã®åŸºç›¤ã¨ãªã‚‹
    - ArgsGeneralWrapper:   ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿é–¢æ•°ï¼Œå…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’å†æ§‹æˆã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã™ã‚‹ã•ã‚Œã¾ã™ï¼Œå…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é †åºã¨æ§‹é€ ã‚’å¤‰æ›´ã™ã‚‹
    - update_ui:            UIã‚’æ›´æ–°ã™ã‚‹ã«ã¯ã€yield from update_uiã‚’ä½¿ç”¨ã™ã‚‹ã—ã¾ã™(chatbot, history)
    - CatchException:       ã™ã¹ã¦ã®å•é¡Œã‚’ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«è¡¨ç¤ºã™ã‚‹
    - HotReload:            ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®ãƒ›ãƒƒãƒˆæ›´æ–°ã‚’å®Ÿç¾ã™ã‚‹
    - trimmed_format_exc:   ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚’å°åˆ·ã™ã‚‹ï¼Œå®‰å…¨ã®ãŸã‚ã«çµ¶å¯¾ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’éš ã™
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
"""


class ChatBotWithCookies(list):
    def __init__(self, cookie):
        """
        cookies = {
            'top_p': top_p,
            'temperature': temperature,
            'lock_plugin': bool,
            "files_to_promote": ["file1", "file2"],
            "most_recent_uploaded": {
                "path": "uploaded_path",
                "time": time.time(),
                "time_str": "timestr",
            }
        }
        """
        self._cookies = cookie

    def write_list(self, list):
        for t in list:
            self.append(t)

    def get_list(self):
        return [t for t in self]

    def get_cookies(self):
        return self._cookies


def ArgsGeneralWrapper(f):
    """
    ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿é–¢æ•°ArgsGeneralWrapperï¼Œå…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒ¼ã‚’å†æ§‹æˆã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã™ã‚‹ã•ã‚Œã¾ã™ï¼Œå…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®é †åºã¨æ§‹é€ ã‚’å¤‰æ›´ã™ã‚‹ã€‚
    è¯¥è£…é¥°å™¨æ˜¯å¤§å¤šæ•°åŠŸèƒ½è°ƒç”¨çš„å…¥å£ã€‚
    å‡½æ•°ç¤ºæ„å›¾ï¼šhttps://mermaid.live/edit#pako:eNqNVFtPGkEY_StkntoEDQtLoTw0sWqapjQxVWPabmOm7AiEZZcsQ9QiiW012qixqdeqqIn10geBh6ZR8PJnmAWe-hc6l3VhrWnLEzNzzvnO953ZyYOYoSIQAWOaMR5LQBN7hvoU3UN_g5iu7imAXEyT4wUF3Pd0dT3y9KGYYUJsmK8V0GPGs0-QjkyojZgwk0Fm82C2dVghX08U8EaoOHjOfoEMU0XmADRhOksVWnNLjdpM82qFzB6S5Q_WWsUhuqCc3JtAsVR_OoMnhyZwXgHWwbS1d4gnsLVZJp-P6mfVxveqAgqC70Jz_pQCOGDKM5xFdNNPDdilF6uSU_hOYqu4a3MHYDZLDzq5fodrC3PWcEaFGPUaRiqJWK_W9g9rvRITa4dhy_0nw67SiePMp3oSR6PPn41DGgllkvkizYwsrmtaejTFd8V4yekGmT1zqrt4XGlAy8WTuiPULF01LksZvukSajfQQRAxmYi5S0D81sDcyzapVdn6sYFHkjhhGyel3frVQnvsnbR23lEjlhIlaOJiFPWzU5G4tfNJo8ejwp47-TbvJkKKZvmxA6SKo16oaazJysfG6klr9T0pbTW2ZqzlL_XaT8fYbQLXe4mSmvoCZXMaa7FePW6s7jVqK9bujvse3WFjY5_Z4KfsA4oiPY4T7Drvn1tLJTbG1to1qR79ulgk89-oJbvZzbIwJty6u20LOReWa9BvwserUd9s9MIKc3x5TUWEoAhUyJK5y85w_yG-dFu_R9waoU7K581y8W_qLle35-rG9Nxcrz8QHRsc0K-r9NViYRT36KsFvCCNzDRMqvSVyzOKAnACpZECIvSvCs2UAhS9QHEwh43BST0GItjMIS_I8e-sLwnj9A262cxA_ZVh0OUY1LJiDSJ5MAEiUijYLUtBORR6KElyQPaCSRDpksNSd8AfluSgHPaFC17wjrOlbgbzyyFf4IFPDvoD_sJvnkdK-g
    """
    def decorated(request: gradio.Request, cookies:dict, max_length:int, llm_model:str,
                  txt:str, txt2:str, top_p:float, temperature:float, chatbot:list,
                  history:list, system_prompt:str, plugin_advanced_arg:str, *args):
        txt_passon = txt
        if txt == "" and txt2 != "": txt_passon = txt2
        # cookieã‚’æŒã¤chatbotã‚’å°å…¥ã™ã‚‹
        if request.username is not None:
            user_name = request.username
        else:
            user_name = default_user_name
        cookies.update({
            'top_p': top_p,
            'api_key': cookies['api_key'],
            'llm_model': llm_model,
            'temperature': temperature,
            'user_name': user_name,
        })
        llm_kwargs = {
            'api_key': cookies['api_key'],
            'llm_model': llm_model,
            'top_p': top_p,
            'max_length': max_length,
            'temperature': temperature,
            'client_ip': request.client.host,
            'most_recent_uploaded': cookies.get('most_recent_uploaded')
        }
        plugin_kwargs = {
            "advanced_arg": plugin_advanced_arg,
        }
        chatbot_with_cookie = ChatBotWithCookies(cookies)
        chatbot_with_cookie.write_list(chatbot)

        if cookies.get('lock_plugin', None) is None:
            # æ­£å¸¸ãªçŠ¶æ…‹
            if len(args) == 0:  # ãƒ—ãƒ©ã‚°ã‚¤ãƒ³é€šé“
                yield from f(txt_passon, llm_kwargs, plugin_kwargs, chatbot_with_cookie, history, system_prompt, request)
            else:               # å¯¹è¯é€šé“ï¼Œã¾ãŸã¯åŸºç¡€åŠŸèƒ½é€šé“
                yield from f(txt_passon, llm_kwargs, plugin_kwargs, chatbot_with_cookie, history, system_prompt, *args)
        else:
            # å¤„ç†å°‘æ•°æƒ…å†µä¸‹çš„ç‰¹æ®Šãƒ—ãƒ©ã‚°ã‚¤ãƒ³çš„é”å®šã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
            module, fn_name = cookies['lock_plugin'].split('->')
            f_hot_reload = getattr(importlib.import_module(module, fn_name), fn_name)
            yield from f_hot_reload(txt_passon, llm_kwargs, plugin_kwargs, chatbot_with_cookie, history, system_prompt, request)
            # åˆ¤æ–­ä¸€ä¸‹ç”¨æˆ·æ˜¯å¦é”™è¯¯åœ°é€šè¿‡å¯¹è¯é€šé“è¿›å…¥ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™è¿›è¡Œæé†’
            final_cookies = chatbot_with_cookie.get_cookies()
            # len(args) != 0 ä»£è¡¨â€œæå‡ºâ€é”®å¯¹è¯é€šé“ï¼Œã¾ãŸã¯åŸºç¡€åŠŸèƒ½é€šé“
            if len(args) != 0 and 'files_to_promote' in final_cookies and len(final_cookies['files_to_promote']) > 0:
                chatbot_with_cookie.append(
                    ["æ¤œå‡ºã•ã‚ŒãŸ**æ»ç•™çš„ç¼“å­˜æ–‡æ¡£**ï¼Œè¯·åŠæ™‚å¤„ç†ã€‚", "è¯·åŠæ™‚ç‚¹å‡»â€œ**ç¾åœ¨ã®å¯¾è©±ã‚’ä¿å­˜ã™ã‚‹**â€è·å–æ‰€æœ‰æ»ç•™æ–‡æ¡£ã€‚"])
                yield from update_ui(chatbot_with_cookie, final_cookies['history'], msg="æ¤œå‡ºã•ã‚ŒãŸè¢«æ»ç•™çš„ç¼“å­˜æ–‡æ¡£")

    return decorated


def update_ui(chatbot:ChatBotWithCookies, history, msg="æ­£å¸¸", **kwargs):  # ç”»é¢ã‚’æ›´æ–°ã™ã‚‹
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æ›´æ–°ã™ã‚‹
    """
    assert isinstance(
        chatbot, ChatBotWithCookies
    ), "Do not discard it in the process of passing chatbotã€‚å¿…è¦ã«å¿œã˜ã¦, clearã‚’ä½¿ç”¨ã™ã‚‹ã—ã¦ã‚¯ãƒªã‚¢ã§ãã¾ã™, for+appendãƒ«ãƒ¼ãƒ—ã‚’ä½¿ç”¨ã™ã‚‹ã—ã¦å€¤ã‚’å†å‰²ã‚Šå½“ã¦ã™ã‚‹ã€‚"
    cookies = chatbot.get_cookies()
    # å¤‡ä»½ä¸€ä»½Historyä½œä¸ºè®°å½•
    cookies.update({"history": history})
    # ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®ãƒ­ãƒƒã‚¯æ™‚ã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹è¡¨ç¤ºã®å•é¡Œã‚’è§£æ±ºã™ã‚‹
    if cookies.get("lock_plugin", None):
        label = (
            cookies.get("llm_model", "")
            + " | "
            + "æ­£åœ¨é”å®šãƒ—ãƒ©ã‚°ã‚¤ãƒ³"
            + cookies.get("lock_plugin", None)
        )
        chatbot_gr = gradio.update(value=chatbot, label=label)
        if cookies.get("label", "") != label:
            cookies["label"] = label  # è®°ä½å½“å‰çš„label
    elif cookies.get("label", None):
        chatbot_gr = gradio.update(value=chatbot, label=cookies.get("llm_model", ""))
        cookies["label"] = None  # ãƒ©ãƒ™ãƒ«ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹
    else:
        chatbot_gr = chatbot

    yield cookies, chatbot_gr, history, msg


def update_ui_lastest_msg(lastmsg:str, chatbot:ChatBotWithCookies, history:list, delay=1):  # ç”»é¢ã‚’æ›´æ–°ã™ã‚‹
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æ›´æ–°ã™ã‚‹
    """
    if len(chatbot) == 0:
        chatbot.append(["update_ui_last_msg", lastmsg])
    chatbot[-1] = list(chatbot[-1])
    chatbot[-1][-1] = lastmsg
    yield from update_ui(chatbot=chatbot, history=history)
    time.sleep(delay)


def trimmed_format_exc():
    import os, traceback

    str = traceback.format_exc()
    current_path = os.getcwd()
    replace_path = "."
    return str.replace(current_path, replace_path)


def CatchException(f):
    """
    ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿é–¢æ•°ï¼Œé–¢æ•°fã§ä¾‹å¤–ã‚’ã‚­ãƒ£ãƒƒãƒã—ã¦ã€ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦è¿”ã™ï¼Œãƒãƒ£ãƒƒãƒˆã«è¡¨ç¤ºã•ã‚Œã‚‹ã€‚
    """

    @wraps(f)
    def decorated(main_input:str, llm_kwargs:dict, plugin_kwargs:dict,
                  chatbot_with_cookie:ChatBotWithCookies, history:list, *args, **kwargs):
        try:
            yield from f(main_input, llm_kwargs, plugin_kwargs, chatbot_with_cookie, history, *args, **kwargs)
        except Exception as e:
            from toolbox import get_conf
            tb_str = '```\n' + trimmed_format_exc() + '```'
            if len(chatbot_with_cookie) == 0:
                chatbot_with_cookie.clear()
                chatbot_with_cookie.append(["ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ã®ä¾‹å¤–", "ç•°å¸¸ã®åŸå› "])
            chatbot_with_cookie[-1] = (chatbot_with_cookie[-1][0], f"[Local Message] ãƒ—ãƒ©ã‚°ã‚¤ãƒ³è°ƒç”¨å‡ºé”™: \n\n{tb_str} \n")
            yield from update_ui(chatbot=chatbot_with_cookie, history=history, msg=f'Exception {e}')  # ç”»é¢ã‚’æ›´æ–°ã™ã‚‹

    return decorated


def HotReload(f):
    """
    HotReloadã®ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼é–¢æ•°ï¼ŒPythoné–¢æ•°ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã®ãƒ›ãƒƒãƒˆæ›´æ–°ã‚’å®Ÿç¾ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã™ã‚‹ã•ã‚Œã¾ã™ã€‚
    é–¢æ•°ã®ãƒ›ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆã¨ã¯ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å®Ÿè¡Œã‚’åœæ­¢ã›ãšã«è¡Œã†ã“ã¨ã‚’æŒ‡ã—ã¾ã™ï¼Œé–¢æ•°ã‚³ãƒ¼ãƒ‰ã‚’æ›´æ–°ã™ã‚‹ï¼Œã“ã‚Œã«ã‚ˆã‚Šã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°æ©Ÿèƒ½ãŒå®Ÿç¾ã•ã‚Œã¾ã™ã€‚
    ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ã®å†…éƒ¨ã§ï¼Œwrapsã‚’ä½¿ç”¨ã™ã‚‹ã™ã‚‹(f)é–¢æ•°ã®ãƒ¡ã‚¿æƒ…å ±ã‚’ä¿æŒã™ã‚‹ãŸã‚ã«ï¼Œå†…éƒ¨é–¢æ•°decoratedã‚’å®šç¾©ã—ã¾ã—ãŸã€‚
    å†…éƒ¨é–¢æ•°ã¯ã€importlibãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®reloadé–¢æ•°ã¨inspectãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®getmoduleé–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹ã—ã¦ã€é–¢æ•°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’å†ãƒ­ãƒ¼ãƒ‰ãŠã‚ˆã³å–å¾—ã—ã¾ã™ï¼Œ
    ãã®å¾Œã€getattré–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹ã—ã¦é–¢æ•°åã‚’å–å¾—ã—ã¾ã™ï¼Œæ–°ã—ã„ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã§é–¢æ•°ã‚’å†èª­ã¿è¾¼ã¿ã™ã‚‹ã€‚
    æœ€å¾Œã«ï¼Œyield fromã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã—ã¦å†èª­ã¿è¾¼ã¿ã•ã‚ŒãŸé–¢æ•°ã‚’è¿”ã™ï¼Œãƒ‡ã‚³ãƒ¬ãƒ¼ãƒˆã•ã‚ŒãŸé–¢æ•°ã§å®Ÿè¡Œã™ã‚‹ã€‚
    æœ€çµ‚çš„ã«ï¼Œãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼é–¢æ•°ã¯å†…éƒ¨é–¢æ•°ã‚’è¿”ã—ã¾ã™ã€‚ã“ã®å†…éƒ¨é–¢æ•°ã¯ã€é–¢æ•°ã®å…ƒã®å®šç¾©ã‚’æœ€æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«æ›´æ–°ã§ãã¾ã™ï¼Œé–¢æ•°ã®æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å®Ÿè¡Œã™ã‚‹ã€‚
    """
    if get_conf("PLUGIN_HOT_RELOAD"):

        @wraps(f)
        def decorated(*args, **kwargs):
            fn_name = f.__name__
            f_hot_reload = getattr(importlib.reload(inspect.getmodule(f)), fn_name)
            yield from f_hot_reload(*args, **kwargs)

        return decorated
    else:
        return f


"""
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
ç¬¬2éƒ¨åˆ†
Other small tools:
    - write_history_to_file:    Write the result to a markdown file
    - regular_txt_to_markdown:  é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’Markdownå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹ã€‚
    - report_exception:         ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã«ç°¡å˜ãªäºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ã™ã‚‹
    - text_divide_paragraph:    ãƒ†ã‚­ã‚¹ãƒˆã‚’æ®µè½åŒºåˆ‡ã‚Šæ–‡å­—ã§åˆ†å‰²ã™ã‚‹ï¼Œæ®µè½ã‚¿ã‚°ã‚’æŒã¤HTMLã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    - markdown_convertion:      è¤‡æ•°ã®ãƒ†ã‚­ã‚¹ãƒˆã®ç¿»è¨³ã‚’çµ„ã¿åˆã‚ã›ã‚‹ï¼ŒMarkdownã‚’ç¾ã—ã„HTMLã«å¤‰æ›ã™ã‚‹
    - format_io:                gradioã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®markdownå‡¦ç†ãƒ†ã‚­ã‚¹ãƒˆã®ç¿»è¨³ã‚’æ¥ç®¡ã™ã‚‹
    - on_file_uploaded:         Handle file uploadï¼ˆè‡ªå‹•è§£å‡ï¼‰
    - on_report_generated:      Automatically project the generated report to the file upload area
    - clip_history:             å±¥æ­´ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã‚‹å ´åˆï¼Œè‡ªå‹•åˆ‡æ–­
    - get_conf:                 è¨­å®šã‚’å–å¾—ã™ã‚‹
    - select_api_key:           ç¾åœ¨ã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦ï¼Œåˆ©ç”¨å¯èƒ½ãªAPIã‚­ãƒ¼ã‚’æŠ½å‡ºã™ã‚‹
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
"""


def get_reduce_token_percent(text:str):
    """
    * ã“ã®é–¢æ•°ã¯ç½®ãæ›ãˆã‚‹æ¥çš„ã«å»ƒæ­¢ã•ã‚Œã¾ã™
    """
    try:
        # text = "maximum context length is 4097 tokens. However, your messages resulted in 4870 tokens"
        pattern = r"(\d+)\s+tokens\b"
        match = re.findall(pattern, text)
        EXCEED_ALLO = 500  # å°‘ã—ä½™è£•ã‚’æŒãŸã›ã‚‹ï¼Œãã†ã—ãªã„ã¨ã€è¿”ä¿¡æ™‚ã«ä½™è£•ãŒå°‘ãªã™ãã¦å•é¡ŒãŒç™ºç”Ÿã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™
        max_limit = float(match[0]) - EXCEED_ALLO
        current_tokens = float(match[1])
        ratio = max_limit / current_tokens
        assert ratio > 0 and ratio < 1
        return ratio, str(int(current_tokens - max_limit))
    except:
        return 0.5, "è©³ç´°ä¸æ˜"


def write_history_to_file(
    history:list, file_basename:str=None, file_fullname:str=None, auto_caption:bool=True
):
    """
    å¯¾è©±å±¥æ­´ã‚’Markdownå½¢å¼ã§ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€ã€‚ãƒ•ã‚¡ã‚¤ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆï¼ŒThen use the current time to generate the file nameã€‚
    """
    import os
    import time

    if file_fullname is None:
        if file_basename is not None:
            file_fullname = pj(get_log_folder(), file_basename)
        else:
            file_fullname = pj(get_log_folder(), f"GPT-Academic-{gen_time_str()}.md")
    os.makedirs(os.path.dirname(file_fullname), exist_ok=True)
    with open(file_fullname, "w", encoding="utf8") as f:
        f.write("# GPT-Academic Report\n")
        for i, content in enumerate(history):
            try:
                if type(content) != str:
                    content = str(content)
            except:
                continue
            if i % 2 == 0 and auto_caption:
                f.write("## ")
            try:
                f.write(content)
            except:
                # remove everything that cannot be handled by utf8
                f.write(content.encode("utf-8", "ignore").decode())
            f.write("\n\n")
    res = os.path.abspath(file_fullname)
    return res


def regular_txt_to_markdown(text:str):
    """
    é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’Markdownå½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹ã€‚
    """
    text = text.replace("\n", "\n\n")
    text = text.replace("\n\n\n", "\n\n")
    text = text.replace("\n\n\n", "\n\n")
    return text


def report_exception(chatbot:ChatBotWithCookies, history:list, a:str, b:str):
    """
    Add error message to chatbot
    """
    chatbot.append((a, b))
    history.extend([a, b])


def find_free_port()->int:
    """
    ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ ã§ä½¿ç”¨ã™ã‚‹å¯èƒ½ãªæœªä½¿ç”¨ã™ã‚‹ã®ãƒãƒ¼ãƒˆã‚’è¿”ã™ã€‚
    """
    import socket
    from contextlib import closing

    with closing(socket.socket(socket.AF_INET, socket.SOCK_STREAM)) as s:
        s.bind(("", 0))
        s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
        return s.getsockname()[1]


def find_recent_files(directory:str)->List[str]:
    """
    Find files that is created with in one minutes under a directory with python, write a function
    """
    import os
    import time

    current_time = time.time()
    one_minute_ago = current_time - 60
    recent_files = []
    if not os.path.exists(directory):
        os.makedirs(directory, exist_ok=True)
    for filename in os.listdir(directory):
        file_path = pj(directory, filename)
        if file_path.endswith(".log"):
            continue
        created_time = os.path.getmtime(file_path)
        if created_time >= one_minute_ago:
            if os.path.isdir(file_path):
                continue
            recent_files.append(file_path)

    return recent_files


def file_already_in_downloadzone(file:str, user_path:str):
    try:
        parent_path = os.path.abspath(user_path)
        child_path = os.path.abspath(file)
        if os.path.samefile(os.path.commonpath([parent_path, child_path]), parent_path):
            return True
        else:
            return False
    except:
        return False


def promote_file_to_downloadzone(file:str, rename_file:str=None, chatbot:ChatBotWithCookies=None):
    # ç½®ãæ›ãˆã‚‹æ–‡ä»¶å¤åˆ¶ä¸€ä»½åˆ°ä¸‹è½½åŒº
    import shutil

    if chatbot is not None:
        user_name = get_user(chatbot)
    else:
        user_name = default_user_name
    if not os.path.exists(file):
        raise FileNotFoundError(f"æ–‡ä»¶{file}ä¸å­˜åœ¨")
    user_path = get_log_folder(user_name, plugin_name=None)
    if file_already_in_downloadzone(file, user_path):
        new_path = file
    else:
        user_path = get_log_folder(user_name, plugin_name="downloadzone")
        if rename_file is None:
            rename_file = f"{gen_time_str()}-{os.path.basename(file)}"
        new_path = pj(user_path, rename_file)
        # æ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆï¼Œãƒ†ã‚­ã‚¹ãƒˆã®ç¿»è¨³
        if os.path.exists(new_path) and not os.path.samefile(new_path, file):
            os.remove(new_path)
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ã™ã‚‹
        if not os.path.exists(new_path):
            shutil.copyfile(file, new_path)
    # åŸå§‹æ–‡æœ¬
    if chatbot is not None:
        if "files_to_promote" in chatbot._cookies:
            current = chatbot._cookies["files_to_promote"]
        else:
            current = []
        if new_path not in current:  # é¿å…æŠŠåŒä¸€piecesæ–‡ä»¶æ·»åŠ å¤šæ¬¡
            chatbot._cookies.update({"files_to_promote": [new_path] + current})
    return new_path


def disable_auto_promotion(chatbot:ChatBotWithCookies):
    chatbot._cookies.update({"files_to_promote": []})
    return


def del_outdated_uploads(outdate_time_seconds:float, target_path_base:str=None):
    if target_path_base is None:
        user_upload_dir = get_conf("PATH_PRIVATE_UPLOAD")
    else:
        user_upload_dir = target_path_base
    current_time = time.time()
    one_hour_ago = current_time - outdate_time_seconds
    # Get a list of all subdirectories in the user_upload_dir folder
    # Remove subdirectories that are older than one hour
    for subdirectory in glob.glob(f"{user_upload_dir}/*"):
        subdirectory_time = os.path.getmtime(subdirectory)
        if subdirectory_time < one_hour_ago:
            try:
                shutil.rmtree(subdirectory)
            except:
                pass
    return



def to_markdown_tabs(head: list, tabs: list, alignment=":---:", column=False, omit_path=None):
    """
    Args:
        head: è¡¨å¤´ï¼š[]
        tabs: è¡¨å€¼ï¼š[[åˆ—1], [åˆ—2], [åˆ—3], [åˆ—4]]
        alignment: :--- å·¦å¯¹é½ï¼Œ :---: å±…ä¸­å¯¹é½ï¼Œ ---: å³å¯¹é½
        column: True to keep data in columns, False to keep data in rows (default).
    Returns:
        A string representation of the markdown table.
    """
    if column:
        transposed_tabs = list(map(list, zip(*tabs)))
    else:
        transposed_tabs = tabs
    # Find the maximum length among the columns
    max_len = max(len(column) for column in transposed_tabs)

    tab_format = "| %s "
    tabs_list = "".join([tab_format % i for i in head]) + "|\n"
    tabs_list += "".join([tab_format % alignment for i in head]) + "|\n"

    for i in range(max_len):
        row_data = [tab[i] if i < len(tab) else "" for tab in transposed_tabs]
        row_data = file_manifest_filter_type(row_data, filter_=None)
        # for dat in row_data:
        #     if (omit_path is not None) and os.path.exists(dat):
        #         dat = os.path.relpath(dat, omit_path)
        tabs_list += "".join([tab_format % i for i in row_data]) + "|\n"

    return tabs_list


def on_file_uploaded(
    request: gradio.Request, files:List[str], chatbot:ChatBotWithCookies,
    txt:str, txt2:str, checkboxes:List[str], cookies:dict
):
    """
    ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã¨ãã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
    """
    if len(files) == 0:
        return chatbot, txt

    # åˆ›å»ºå·¥ä½œè·¯å¾„
    user_name = default_user_name if not request.username else request.username
    time_tag = gen_time_str()
    target_path_base = get_upload_folder(user_name, tag=time_tag)
    os.makedirs(target_path_base, exist_ok=True)

    # ç§»é™¤è¿‡æ™‚çš„æ—§æ–‡ä»¶ä»è€ŒèŠ‚çœç©ºé—´&ä¿æŠ¤éšç§
    outdate_time_seconds = 3600  # ä¸€å°æ™‚
    del_outdated_uploads(outdate_time_seconds, get_upload_folder(user_name))

    # é€piecesæ–‡ä»¶è½¬ç§»åˆ°ç›®æ ‡è·¯å¾„
    upload_msg = ""
    for file in files:
        file_origin_name = os.path.basename(file.orig_name)
        this_file_path = pj(target_path_base, file_origin_name)
        shutil.move(file.name, this_file_path)
        upload_msg += extract_archive(
            file_path=this_file_path, dest_dir=this_file_path + ".extract"
        )

    # æ•´ç†æ–‡ä»¶é›†åˆ å‡ºåŠ›æ¶ˆæ¯
    files = glob.glob(f"{target_path_base}/**/*", recursive=True)
    moved_files = [fp for fp in files]
    max_file_to_show = 10
    if len(moved_files) > max_file_to_show:
        moved_files = moved_files[:max_file_to_show//2] + [f'... ( ğŸ“Œçœç•¥{len(moved_files) - max_file_to_show}piecesæ–‡ä»¶çš„æ˜¾ç¤º ) ...'] + \
                      moved_files[-max_file_to_show//2:]
    moved_files_str = to_markdown_tabs(head=["æ–‡ä»¶"], tabs=[moved_files], omit_path=target_path_base)
    chatbot.append(
        [
            "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼Œå—ä¿¡ç®±ã‚’ç¢ºèªã—ã¦ãã ã•ã„",
            f"[Local Message] ä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å—ã‘å–ã‚Šã¾ã—ãŸ ï¼ˆä¸Šä¼ åˆ°è·¯å¾„ï¼š{target_path_base}ï¼‰: " +
            f"\n\n{moved_files_str}" +
            f"\n\nå‘¼ã³å‡ºã—ãƒ‘ã‚¹ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒè‡ªå‹•çš„ã«ä¿®æ­£ã•ã‚Œã¾ã—ãŸ: \n\n{txt}" +
            f"\n\nä»Šæ‚¨ç‚¹å‡»ä»»æ„é–¢æ•°ãƒ—ãƒ©ã‚°ã‚¤ãƒ³æ™‚ï¼Œä¸Šè¨˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦ä½¿ç”¨ã™ã‚‹ã•ã‚Œã¾ã™" +
            upload_msg,
        ]
    )

    txt, txt2 = target_path_base, ""
    if "æµ®åŠ¨å…¥åŠ›ã‚¨ãƒªã‚¢" in checkboxes:
        txt, txt2 = txt2, txt

    # è®°å½•è¿‘æœŸæ–‡ä»¶
    cookies.update(
        {
            "most_recent_uploaded": {
                "path": target_path_base,
                "time": time.time(),
                "time_str": time_tag,
            }
        }
    )
    return chatbot, txt, txt2, cookies


def on_report_generated(cookies:dict, files:List[str], chatbot:ChatBotWithCookies):
    # from toolbox import find_recent_files
    # PATH_LOGGING = get_conf('PATH_LOGGING')
    if "files_to_promote" in cookies:
        report_files = cookies["files_to_promote"]
        cookies.pop("files_to_promote")
    else:
        report_files = []
    #     report_files = find_recent_files(PATH_LOGGING)
    if len(report_files) == 0:
        return cookies, None, chatbot
    # files.extend(report_files)
    file_links = ""
    for f in report_files:
        file_links += (
            f'<br/><a href="file={os.path.abspath(f)}" target="_blank">{f}</a>'
        )
    chatbot.append(["å ±å‘Šã®ãƒªãƒ¢ãƒ¼ãƒˆå–å¾—ãƒ†ã‚­ã‚¹ãƒˆã®ç¿»è¨³ï¼Ÿ", f"å ±å‘Šã¯å³å´ã®ã€Œãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒªã‚¢ã€ã«è¿½åŠ ã•ã‚Œã¾ã—ãŸï¼ˆæŠ˜ã‚ŠãŸãŸã¿çŠ¶æ…‹ã«ãªã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼‰ï¼Œå—ä¿¡ç®±ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚{file_links}"])
    return cookies, report_files, chatbot


def load_chat_cookies():
    API_KEY, LLM_MODEL, AZURE_API_KEY = get_conf(
        "API_KEY", "LLM_MODEL", "AZURE_API_KEY"
    )
    AZURE_CFG_ARRAY, NUM_CUSTOM_BASIC_BTN = get_conf(
        "AZURE_CFG_ARRAY", "NUM_CUSTOM_BASIC_BTN"
    )

    # deal with azure openai key
    if is_any_api_key(AZURE_API_KEY):
        if is_any_api_key(API_KEY):
            API_KEY = API_KEY + "," + AZURE_API_KEY
        else:
            API_KEY = AZURE_API_KEY
    if len(AZURE_CFG_ARRAY) > 0:
        for azure_model_name, azure_cfg_dict in AZURE_CFG_ARRAY.items():
            if not azure_model_name.startswith("azure"):
                raise ValueError("AZURE_CFG_ARRAYä¸­é…ç½®çš„æ¨¡å‹å¿…é¡»ä»¥azureå¼€å¤´")
            AZURE_API_KEY_ = azure_cfg_dict["AZURE_API_KEY"]
            if is_any_api_key(AZURE_API_KEY_):
                if is_any_api_key(API_KEY):
                    API_KEY = API_KEY + "," + AZURE_API_KEY_
                else:
                    API_KEY = AZURE_API_KEY_

    customize_fn_overwrite_ = {}
    for k in range(NUM_CUSTOM_BASIC_BTN):
        customize_fn_overwrite_.update(
            {
                "è‡ªå®šä¹‰æŒ‰é’®"
                + str(k + 1): {
                    "Title": r"",
                    "Prefix": r"è¯·åœ¨è‡ªå®šä¹‰èœå•ä¸­å®šä¹‰ãƒ’ãƒ³ãƒˆè¯ãƒ†ã‚­ã‚¹ãƒˆã®ç¿»è¨³.",
                    "Suffix": r"è¯·åœ¨è‡ªå®šä¹‰èœå•ä¸­å®šä¹‰ãƒ’ãƒ³ãƒˆè¯åç¼€",
                }
            }
        )
    return {
        "api_key": API_KEY,
        "llm_model": LLM_MODEL,
        "customize_fn_overwrite": customize_fn_overwrite_,
    }


def clear_line_break(txt):
    txt = txt.replace("\n", " ")
    txt = txt.replace("  ", " ")
    txt = txt.replace("  ", " ")
    return txt


class DummyWith:
    """
    ã“ã®ã‚³ãƒ¼ãƒ‰ã¯ã€DummyWithã¨ã„ã†åå‰ã®ç©ºã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ã‚’å®šç¾©ã—ã¦ã„ã¾ã™ï¼Œ
    ãã®å½¹å‰²ã¯â€¦â€¦ã‚ã‚â€¦â€¦æ©Ÿèƒ½ã—ãªã„ã“ã¨ã§ã™ï¼ŒThat is, replace other context managers without changing the code structureã€‚
    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ã¯Pythonã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ä¸€ç¨®ã§ã™ï¼Œwithæ–‡ã¨ä¸€ç·’ã«ä½¿ç”¨ã™ã‚‹ã™ã‚‹ï¼Œ
    ã„ãã¤ã‹ã®ãƒªã‚½ãƒ¼ã‚¹ãŒã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®å®Ÿè¡Œä¸­ã«æ­£ã—ãåˆæœŸåŒ–ãŠã‚ˆã³ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã€‚
    ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ã¯2ã¤ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å®Ÿè£…ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ï¼ŒThey are __enter__ respectively()ã¨ __exit__()ã€‚
    When the context execution startsï¼Œ__enter__()ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ãŒå®Ÿè¡Œã•ã‚Œã‚‹å‰ã«å‘¼ã³å‡ºã•ã‚Œã¾ã™ï¼Œ
    While at the end of the context executionï¼Œ__exit__()ãƒ¡ã‚½ãƒƒãƒ‰ãŒå‘¼ã³å‡ºã•ã‚Œã¾ã™ã€‚
    """

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        return


def run_gradio_in_subpath(demo, auth, port, custom_path):
    """
    Gradioã®å®Ÿè¡Œã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’æŒ‡å®šã•ã‚ŒãŸ2æ¬¡ãƒ‘ã‚¹ã«å¤‰æ›´ã™ã‚‹
    """

    def is_path_legal(path: str) -> bool:
        """
        check path for sub url
        path: path to check
        return value: do sub url wrap
        """
        if path == "/":
            return True
        if len(path) == 0:
            print(
                "ilegal custom path: {}\npath must not be empty\ndeploy on root url".format(
                    path
                )
            )
            return False
        if path[0] == "/":
            if path[1] != "/":
                print("deploy on sub-path {}".format(path))
                return True
            return False
        print(
            "ilegal custom path: {}\npath should begin with '/'\ndeploy on root url".format(
                path
            )
        )
        return False

    if not is_path_legal(custom_path):
        raise RuntimeError("Ilegal custom path")
    import uvicorn
    import gradio as gr
    from fastapi import FastAPI

    app = FastAPI()
    if custom_path != "/":

        @app.get("/")
        def read_main():
            return {"message": f"Gradio is running at: {custom_path}"}

    app = gr.mount_gradio_app(app, demo, path=custom_path)
    uvicorn.run(app, host="0.0.0.0", port=port)  # , auth=auth


def clip_history(inputs, history, tokenizer, max_token_limit):
    """
    reduce the length of history by clipping.
    this function search for the longest entries to clip, little by little,
    until the number of token of history is reduced under threshold.
    å±¥æ­´ã®é•·ã•ã‚’çŸ­ãã™ã‚‹ãŸã‚ã«ãƒˆãƒªãƒŸãƒ³ã‚°ã‚’ä½¿ç”¨ã™ã‚‹ã™ã‚‹ã€‚
    ã“ã®é–¢æ•°ã¯å¾ã€…ã«æœ€é•·ã®ã‚¨ãƒ³ãƒˆãƒªã‚’æ¤œç´¢ã—ã¦ç·¨é›†ã—ã¾ã™ï¼Œ
    ç›´åˆ°å±¥æ­´ã®ãƒãƒ¼ã‚¯æ•°ãŒé–¾å€¤ä»¥ä¸‹ã«ãªã‚‹ã¾ã§ã€‚
    """
    import numpy as np
    from request_llms.bridge_all import model_info

    def get_token_num(txt):
        return len(tokenizer.encode(txt, disallowed_special=()))

    input_token_num = get_token_num(inputs)

    if max_token_limit < 5000:
        output_token_expect = 256  # 4k & 2k models
    elif max_token_limit < 9000:
        output_token_expect = 512  # 8k models
    else:
        output_token_expect = 1024  # 16k & 32k models

    if input_token_num < max_token_limit * 3 / 4:
        # å…¥åŠ›éƒ¨åˆ†ã®ãƒˆãƒ¼ã‚¯ãƒ³ã®å‰²åˆãŒåˆ¶é™ã®3/4æœªæº€ã®å ´åˆï¼ŒãƒˆãƒªãƒŸãƒ³ã‚°ä¸­
        # 1. å…¥åŠ›ã®ä½™è£•ã‚’æ®‹ã™
        max_token_limit = max_token_limit - input_token_num
        # 2. Leave room for the output
        max_token_limit = max_token_limit - output_token_expect
        # 3. ã‚‚ã—ä½™å‰°ãŒå°‘ãªã™ãã‚‹å ´åˆï¼Œå±¥æ­´ã‚’ç›´æ¥ã‚¯ãƒªã‚¢ã™ã‚‹
        if max_token_limit < output_token_expect:
            history = []
            return history
    else:
        # When the token proportion of the input part is > åˆ¶é™ã®3/4æ™‚ï¼Œå±¥æ­´ã‚’ç›´æ¥ã‚¯ãƒªã‚¢ã™ã‚‹
        history = []
        return history

    everything = [""]
    everything.extend(history)
    n_token = get_token_num("\n".join(everything))
    everything_token = [get_token_num(e) for e in everything]

    # åˆ‡ã‚Šæ¨ã¦æ™‚ã®ç²’åº¦
    delta = max(everything_token) // 16

    while n_token > max_token_limit:
        where = np.argmax(everything_token)
        encoded = tokenizer.encode(everything[where], disallowed_special=())
        clipped_encoded = encoded[: len(encoded) - delta]
        everything[where] = tokenizer.decode(clipped_encoded)[
            :-1
        ]  # -1 to remove the may-be illegal char
        everything_token[where] = get_token_num(everything[where])
        n_token = get_token_num("\n".join(everything))

    history = everything[1:]
    return history


"""
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
ç¬¬3éƒ¨åˆ†
Other small tools:
    - zip_folder:    æŠŠæŸpiecesè·¯å¾„ä¸‹æ‰€æœ‰æ–‡ä»¶å‹ç¼©ï¼Œãƒ†ã‚­ã‚¹ãƒˆã®ç¿»è¨³ï¼ˆgptã§æ›¸ã‹ã‚ŒãŸï¼‰
    - gen_time_str:  ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ç”Ÿæˆ
    - ProxyNetworkActivate: ä¸´æ™‚åœ°å¯åŠ¨ä»£ç†ç½‘ç»œï¼ˆã‚ã‚‹å ´åˆï¼‰
    - objdump/objload: ä¾¿åˆ©ãªãƒ‡ãƒãƒƒã‚°é–¢æ•°
=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-
"""


def zip_folder(source_folder, dest_folder, zip_name):
    import zipfile
    import os

    # Make sure the source folder exists
    if not os.path.exists(source_folder):
        print(f"{source_folder} does not exist")
        return

    # Make sure the destination folder exists
    if not os.path.exists(dest_folder):
        print(f"{dest_folder} does not exist")
        return

    # Create the name for the zip file
    zip_file = pj(dest_folder, zip_name)

    # Create a ZipFile object
    with zipfile.ZipFile(zip_file, "w", zipfile.ZIP_DEFLATED) as zipf:
        # Walk through the source folder and add files to the zip file
        for foldername, subfolders, filenames in os.walk(source_folder):
            for filename in filenames:
                filepath = pj(foldername, filename)
                zipf.write(filepath, arcname=os.path.relpath(filepath, source_folder))

    # Move the zip file to the destination folder (if it wasn't already there)
    if os.path.dirname(zip_file) != dest_folder:
        os.rename(zip_file, pj(dest_folder, os.path.basename(zip_file)))
        zip_file = pj(dest_folder, os.path.basename(zip_file))

    print(f"Zip file created at {zip_file}")


def zip_result(folder):
    t = gen_time_str()
    zip_folder(folder, get_log_folder(), f"{t}-result.zip")
    return pj(get_log_folder(), f"{t}-result.zip")


def gen_time_str():
    import time

    return time.strftime("%Y-%m-%d-%H-%M-%S", time.localtime())


def get_log_folder(user=default_user_name, plugin_name="shared"):
    if user is None:
        user = default_user_name
    PATH_LOGGING = get_conf("PATH_LOGGING")
    if plugin_name is None:
        _dir = pj(PATH_LOGGING, user)
    else:
        _dir = pj(PATH_LOGGING, user, plugin_name)
    if not os.path.exists(_dir):
        os.makedirs(_dir)
    return _dir


def get_upload_folder(user=default_user_name, tag=None):
    PATH_PRIVATE_UPLOAD = get_conf("PATH_PRIVATE_UPLOAD")
    if user is None:
        user = default_user_name
    if tag is None or len(tag) == 0:
        target_path_base = pj(PATH_PRIVATE_UPLOAD, user)
    else:
        target_path_base = pj(PATH_PRIVATE_UPLOAD, user, tag)
    return target_path_base


def is_the_upload_folder(string):
    PATH_PRIVATE_UPLOAD = get_conf("PATH_PRIVATE_UPLOAD")
    pattern = r"^PATH_PRIVATE_UPLOAD[\\/][A-Za-z0-9_-]+[\\/]\d{4}-\d{2}-\d{2}-\d{2}-\d{2}-\d{2}$"
    pattern = pattern.replace("PATH_PRIVATE_UPLOAD", PATH_PRIVATE_UPLOAD)
    if re.match(pattern, string):
        return True
    else:
        return False


def get_user(chatbotwithcookies:ChatBotWithCookies):
    return chatbotwithcookies._cookies.get("user_name", default_user_name)


class ProxyNetworkActivate:
    """
    è¿™æ®µä»£ç å®šä¹‰äº†ä¸€piecesåä¸ºProxyNetworkActivateçš„ç©ºæ–‡è„ˆç®¡ç†å™¨, ä¸€éƒ¨ã®ã‚³ãƒ¼ãƒ‰ã«ãƒ—ãƒ­ã‚­ã‚·ã‚’é©ç”¨ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã™ã‚‹ã•ã‚Œã¾ã™
    """

    def __init__(self, task=None) -> None:
        self.task = task
        if not task:
            # ä¸ç»™å®štask, é‚£ä¹ˆç§ãŸã¡ã¯#ä»£ç†ç”Ÿæ•ˆ
            self.valid = True
        else:
            # ç»™å®šäº†task, ç§ãŸã¡ã¯æ£€æŸ¥ä¸€ä¸‹
            from toolbox import get_conf

            WHEN_TO_USE_PROXY = get_conf("WHEN_TO_USE_PROXY")
            self.valid = task in WHEN_TO_USE_PROXY

    def __enter__(self):
        if not self.valid:
            return self
        from toolbox import get_conf

        proxies = get_conf("proxies")
        if "no_proxy" in os.environ:
            os.environ.pop("no_proxy")
        if proxies is not None:
            if "http" in proxies:
                os.environ["HTTP_PROXY"] = proxies["http"]
            if "https" in proxies:
                os.environ["HTTPS_PROXY"] = proxies["https"]
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        os.environ["no_proxy"] = "*"
        if "HTTP_PROXY" in os.environ:
            os.environ.pop("HTTP_PROXY")
        if "HTTPS_PROXY" in os.environ:
            os.environ.pop("HTTPS_PROXY")
        return


def objdump(obj, file="objdump.tmp"):
    import pickle

    with open(file, "wb+") as f:
        pickle.dump(obj, f)
    return


def objload(file="objdump.tmp"):
    import pickle, os

    if not os.path.exists(file):
        return
    with open(file, "rb") as f:
        return pickle.load(f)


def Singleton(cls):
    """
    å˜ä¸€ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿
    """
    _instance = {}

    def _singleton(*args, **kargs):
        if cls not in _instance:
            _instance[cls] = cls(*args, **kargs)
        return _instance[cls]

    return _singleton


def get_pictures_list(path):
    file_manifest = [f for f in glob.glob(f"{path}/**/*.jpg", recursive=True)]
    file_manifest += [f for f in glob.glob(f"{path}/**/*.jpeg", recursive=True)]
    file_manifest += [f for f in glob.glob(f"{path}/**/*.png", recursive=True)]
    return file_manifest


def have_any_recent_upload_image_files(chatbot:ChatBotWithCookies):
    _5min = 5 * 60
    if chatbot is None:
        return False, None  # chatbot is None
    most_recent_uploaded = chatbot._cookies.get("most_recent_uploaded", None)
    if not most_recent_uploaded:
        return False, None  # most_recent_uploaded is None
    if time.time() - most_recent_uploaded["time"] < _5min:
        most_recent_uploaded = chatbot._cookies.get("most_recent_uploaded", None)
        path = most_recent_uploaded["path"]
        file_manifest = get_pictures_list(path)
        if len(file_manifest) == 0:
            return False, None
        return True, file_manifest  # most_recent_uploaded is new
    else:
        return False, None  # most_recent_uploaded is too old

# Claude3 model supports graphic context dialogue, reads all images
def every_image_file_in_path(chatbot:ChatBotWithCookies):
    if chatbot is None:
        return False, []  # chatbot is None
    most_recent_uploaded = chatbot._cookies.get("most_recent_uploaded", None)
    if not most_recent_uploaded:
        return False, []  # most_recent_uploaded is None
    path = most_recent_uploaded["path"]
    file_manifest = get_pictures_list(path)
    if len(file_manifest) == 0:
        return False, []
    return True, file_manifest

# Function to encode the image
def encode_image(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")


def get_max_token(llm_kwargs):
    from request_llms.bridge_all import model_info

    return model_info[llm_kwargs["llm_model"]]["max_token"]


def check_packages(packages=[]):
    import importlib.util

    for p in packages:
        spam_spec = importlib.util.find_spec(p)
        if spam_spec is None:
            raise ModuleNotFoundError


def map_file_to_sha256(file_path):
    import hashlib

    with open(file_path, 'rb') as file:
        content = file.read()

    # Calculate the SHA-256 hash of the file contents
    sha_hash = hashlib.sha256(content).hexdigest()

    return sha_hash


def check_repeat_upload(new_pdf_path, pdf_hash):
    '''
    æ£€æŸ¥Historyä¸Šä¼ ã®ãƒ•ã‚¡ã‚¤ãƒ«æ˜¯å¦ä¸æ–°ä¸Šä¼ ã®ãƒ•ã‚¡ã‚¤ãƒ«ç›¸åŒï¼Œå¦‚æœç›¸åŒåˆ™æˆ»ã‚‹(True, é‡å¤æ–‡ä»¶è·¯å¾„)ï¼Œå¦åˆ™æˆ»ã‚‹(Falseï¼ŒNone)
    '''
    from toolbox import get_conf
    import PyPDF2

    user_upload_dir = os.path.dirname(os.path.dirname(new_pdf_path))
    file_name = os.path.basename(new_pdf_path)

    file_manifest = [f for f in glob.glob(f'{user_upload_dir}/**/{file_name}', recursive=True)]

    for saved_file in file_manifest:
        with open(new_pdf_path, 'rb') as file1, open(saved_file, 'rb') as file2:
            reader1 = PyPDF2.PdfFileReader(file1)
            reader2 = PyPDF2.PdfFileReader(file2)

            # æ¯”è¾ƒé¡µæ•°æ˜¯å¦ç›¸åŒ
            if reader1.getNumPages() != reader2.getNumPages():
                continue

            # æ¯”è¾ƒæ¯ä¸€é¡µçš„å†…å®¹æ˜¯å¦ç›¸åŒ
            for page_num in range(reader1.getNumPages()):
                page1 = reader1.getPage(page_num).extractText()
                page2 = reader2.getPage(page_num).extractText()
                if page1 != page2:
                    continue

        maybe_project_dir = glob.glob('{}/**/{}'.format(get_log_folder(), pdf_hash + ".tag"), recursive=True)


        if len(maybe_project_dir) > 0:
            return True, os.path.dirname(maybe_project_dir[0])

    # å¦‚æœæ‰€æœ‰é¡µçš„å†…å®¹éƒ½ç›¸åŒï¼Œæˆ»ã‚‹ True
    return False, None

def log_chat(llm_model: str, input_str: str, output_str: str):
    if output_str and input_str and llm_model:
        uid = str(uuid.uuid4().hex)
        logging.info(f"[Model({uid})] {llm_model}")
        input_str = input_str.rstrip('\n')
        logging.info(f"[Query({uid})]\n{input_str}")
        output_str = output_str.rstrip('\n')
        logging.info(f"[Response({uid})]\n{output_str}\n\n")
